{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_data(*path: str, labels: list, skip: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Loads data from a given path and returns a numpy array with the image and label of each file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path: str -> Path to the data folder. (can be multiple paths)\n",
    "    labels: list -> List of labels for each path.\n",
    "    skip: bool -> Skip files that are not images or cannot be read. (default: True)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    data_array: np.ndarray -> Numpy array with the image and label of each file.\n",
    "    \"\"\"\n",
    "\n",
    "    # list to store the data. \n",
    "    data_array = []\n",
    "    skipped_files = 0 # Number of skipped files.\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Check if the number of paths and labels are equal.\n",
    "    # If not equal raise an error.\n",
    "    # ---------------------------------------------------\n",
    "    if len(path) == len(labels):\n",
    "\n",
    "        # Loop through the paths and labels.\n",
    "        for p, l in zip(path, labels):\n",
    "\n",
    "            # --------------------------\n",
    "            # Check if the path exists.\n",
    "            # If not raise an error.\n",
    "            # --------------------------    \n",
    "            if os.path.exists(p):\n",
    "                \n",
    "                # ----------------------------------------------\n",
    "                # Loop through the files in the path.\n",
    "                # Append the image and label to the list.\n",
    "                # ----------------------------------------------\n",
    "                for file in os.listdir(p):\n",
    "                    # Try to catch errors when reading the image.\n",
    "                    try:\n",
    "                        # Append the image and label to the list.\n",
    "                        data_array.append([Image.open(os.path.join(p, file)), l])\n",
    "\n",
    "                    except Image.UnidentifiedImageError as e:\n",
    "                        # If skip is True, skip the file.\n",
    "                        if skip:\n",
    "                            skipped_files += 1 \n",
    "                        else:\n",
    "                            raise e\n",
    "            else:\n",
    "                raise FileNotFoundError(\"Path does not exist\")\n",
    "    else:\n",
    "        raise ValueError(\"Number of paths and labels must be equal\")\n",
    "    \n",
    "    if skipped_files > 0:\n",
    "        print(f\"Skipped {skipped_files} files\")\n",
    "\n",
    "    # Return the numpy array.\n",
    "    return np.array(data_array, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 389 files\n",
      "dataset len: 4773\n",
      "dataset shape: (4773, 2)\n",
      "dataset fire images: 2111\n",
      "dataset forest images: 2662\n"
     ]
    }
   ],
   "source": [
    "path_fire = './Data/fire/fire/fire-images/'\n",
    "path_forest = './Data/fire/fire/forest-images/'\n",
    "\n",
    "dataset = load_data(path_fire, path_forest, labels=['fire', 'forest'])\n",
    "\n",
    "print(f\"dataset len: {len(dataset)}\")\n",
    "print(f\"dataset shape: {dataset.shape}\")\n",
    "print(f\"dataset fire images: {len([index for index in dataset if index[1] == 'fire'])}\")\n",
    "print(f\"dataset forest images: {len([index for index in dataset if index[1] == 'forest'])}\")\n",
    "\n",
    "# TODO: resize images to 256x256\n",
    "# TODO: Print sample images\n",
    "# TODO: shuffle dataset\n",
    "# TODO: split dataset into train, validation and test sets\n",
    "# TODO: make model\n",
    "# TODO: train model\n",
    "# TODO: test model\n",
    "# TODO: save model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_Deep_Learning-8qSyIK8g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
